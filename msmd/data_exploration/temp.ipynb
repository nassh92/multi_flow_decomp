{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Just compare to see if it makes sense\n",
    "\"\"\"\n",
    "\n",
    "# Import pickle\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\HADDAM\\\\Documents\\\\Python Scripts\\\\multi_flow_decomp\\\\')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "{\"res_key_metadata\":res_key_metadata,\n",
    "\"res_value_metadata\":res_value_metadata, \n",
    "\"data\":deepcopy(dict(dict_results))}\n",
    "\"\"\"\n",
    "with open(\"results/simulated/MFDS_vs_RL/results_test/results_rl_heuristics.pickle\", \n",
    "          'rb') as handle:\n",
    "    file = pickle.load(handle)\n",
    "    test_infos = file[\"res_key_metadata\"]\n",
    "    metric_names = file[\"res_value_metadata\"]\n",
    "    data = file[\"data\"]\n",
    "\n",
    "\"\"\"\n",
    "dict_results[(ind_instance, test_infos)] = (flow_val_res, flow_res, \n",
    "                                            m_flow_res, prop_fsupp, \n",
    "                                            prop_sp, trans_func_res)\n",
    "test_infos = (path_type_selector, path_card_criteria, lr_rate, (coeff1, coeff2, coeff3))\n",
    "\"\"\"\n",
    "\n",
    "# Filter to leave only the best value of the learning parameter\n",
    "data_res_rl, inserted = {}, set()\n",
    "for ind_instance, test_infos in data:\n",
    "    # Unpack\n",
    "    flow_val_res, flow_res, _, _, _, trans_func_res, reward = data[(ind_instance, test_infos)]\n",
    "    path_type_selector, path_card_criteria, lr_rate = test_infos[0], test_infos[1], test_infos[2]\n",
    "    coeff1, coeff2, coeff3 = test_infos[-1]\n",
    "    # The key to be (potentially) inserted\n",
    "    key_inserted = (ind_instance, (path_type_selector, \n",
    "                                   path_card_criteria, \n",
    "                                   (coeff1, coeff2, coeff3)))\n",
    "    # Insert key if not present else delete it\n",
    "    if key_inserted not in data_res_rl:\n",
    "        data_res_rl[key_inserted] = data[(ind_instance, test_infos)]+(reward, lr_rate)\n",
    "    elif reward > data_res_rl[key_inserted][-2]: \n",
    "        del data_res_rl[key_inserted]\n",
    "        data_res_rl[key_inserted] = data[(ind_instance, test_infos)]+(reward, lr_rate)\n",
    "\n",
    "\n",
    "# Unzip to display (each metric on one list)\n",
    "nb_instances = len({id_inst for id_inst, _ in data_res_rl.keys()})\n",
    "ls_test_infos = list(set([e[1] for e in data_res_rl.keys()]))\n",
    "dict_perfs_rl = {ls_test_infos[i]:[] for i in range(len(ls_test_infos))}\n",
    "for test_info in ls_test_infos:\n",
    "    metrics_instances = dict_perfs_rl[test_info]\n",
    "    for j in range(len(metric_names)):\n",
    "        metrics_instances.append([(id_inst, \n",
    "                                   data_res_rl[(id_inst, test_info)][j]) \n",
    "                                        for id_inst in range(nb_instances)])\n",
    "        metrics_instances[-1].sort(key = lambda x : -x[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"results/simulated/MFDS_vs_RL/results_test/results_rl_heuristics_original.pickle\", \n",
    "          'rb') as handle:\n",
    "    file = pickle.load(handle)\n",
    "    test_infos = file[\"res_key_metadata\"]\n",
    "    metric_names = file[\"res_value_metadata\"]\n",
    "    data = file[\"data\"]\n",
    "\n",
    "\"\"\"\n",
    "dict_results[(ind_instance, test_infos)] = (flow_val_res, flow_res, \n",
    "                                            m_flow_res, prop_fsupp, \n",
    "                                            prop_sp, trans_func_res)\n",
    "test_infos = (path_type_selector, path_card_criteria, lr_rate, (coeff1, coeff2, coeff3))\n",
    "\"\"\"\n",
    "\n",
    "# Filter to leave only the best value of the learning parameter\n",
    "data_res_rl2, inserted = {}, set()\n",
    "for ind_instance, test_infos in data:\n",
    "    # Unpack\n",
    "    flow_val_res, flow_res, _, _, _, trans_func_res, reward = data[(ind_instance, test_infos)]\n",
    "    path_type_selector, path_card_criteria, lr_rate = test_infos[0], test_infos[1], test_infos[2]\n",
    "    coeff1, coeff2, coeff3 = test_infos[-1]\n",
    "    # The key to be (potentially) inserted\n",
    "    key_inserted = (ind_instance, (path_type_selector, \n",
    "                                   path_card_criteria, \n",
    "                                   (coeff1, coeff2, coeff3)))\n",
    "    # Insert key if not present else delete it\n",
    "    if key_inserted not in data_res_rl2:\n",
    "        data_res_rl2[key_inserted] = data[(ind_instance, test_infos)]+(reward, lr_rate)\n",
    "    elif reward > data_res_rl2[key_inserted][-2]: \n",
    "        del data_res_rl2[key_inserted]\n",
    "        data_res_rl2[key_inserted] = data[(ind_instance, test_infos)]+(reward, lr_rate)\n",
    "\n",
    "\n",
    "# Unzip to display (each metric on one list)\n",
    "nb_instances = len({id_inst for id_inst, _ in data_res_rl2.keys()})\n",
    "ls_test_infos = list(set([e[1] for e in data_res_rl2.keys()]))\n",
    "dict_perfs_rl2 = {ls_test_infos[i]:[] for i in range(len(ls_test_infos))}\n",
    "for test_info in ls_test_infos:\n",
    "    metrics_instances2 = dict_perfs_rl2[test_info]\n",
    "    for j in range(len(metric_names)):\n",
    "        metrics_instances2.append([(id_inst, \n",
    "                                   data_res_rl2[(id_inst, test_info)][j]) \n",
    "                                        for id_inst in range(nb_instances)])\n",
    "        metrics_instances2[-1].sort(key = lambda x : -x[1])\n",
    "\n",
    "\n",
    "\n",
    "# Diplay the curves\n",
    "#!!! REECRITURE !!!\n",
    "save_path = \"results/simulated/MFDS_vs_RL/results_test/rl_heuristics_test/\"\n",
    "colors = ['b', 'g', 'k', 'r', 'y', 'brown', 'purple', 'orange',  'gray', 'pink']\n",
    "for i in range(len(metric_names)):\n",
    "    fig = plt.figure()\n",
    "    test_info = \"rl_arc_based\", \"one_for_each\", (0.33, 0.33, 0.34)\n",
    "    path_type_selector, path_card_criteria, (coeff1, coeff2, coeff3) = test_info\n",
    "\n",
    "\n",
    "    # Construct list of values of the metric for each instance\n",
    "    vals = [e[1] for e in dict_perfs_rl[test_info][i]]\n",
    "    # Process mean and reward\n",
    "    mean_ = np.mean(vals)\n",
    "    std_ = np.std(vals)\n",
    "    name = path_type_selector+\" \"+path_card_criteria+\" \"+\" c3=\"+str(coeff3)\n",
    "    plt.scatter(list(range(len(dict_perfs_rl[test_info][i]))), \n",
    "                vals, \n",
    "                color = colors[0], \n",
    "                alpha = 0.5, \n",
    "                label = name+\" 111 \"+str(round(mean_,3))+\"+/-\"+str(round(std_,3)))\n",
    "    \n",
    "\n",
    "    # Construct list of values of the metric for each instance\n",
    "    vals = [e[1] for e in dict_perfs_rl2[test_info][i]]\n",
    "    # Process mean and reward\n",
    "    mean_ = np.mean(vals)\n",
    "    std_ = np.std(vals)\n",
    "    name = path_type_selector+\" \"+path_card_criteria+\" \"+\" c3=\"+str(coeff3)\n",
    "    plt.scatter(list(range(len(dict_perfs_rl2[test_info][i]))), \n",
    "                vals, \n",
    "                color = colors[1], \n",
    "                alpha = 0.5, \n",
    "                label = name+\" 222 \"+str(round(mean_,3))+\"+/-\"+str(round(std_,3)))\n",
    "    \n",
    "\n",
    "    plt.xlabel(\"Instances\")\n",
    "    plt.ylabel(metric_names[i])\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    if save_path:\n",
    "        fig.savefig(os.path.join(save_path, \n",
    "                                \"comp_general_rl_heurs_\"+metric_names[i]), \n",
    "                                bbox_inches='tight', \n",
    "                                pad_inches=0)\n",
    "    plt.close(fig)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
